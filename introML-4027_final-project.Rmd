---
title: "introML-4027_final-project"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

require(ggplot2)
require(lattice)
require(e1071)
require(caret)

library(pROC)
library(dplyr)
library(ranger)
set.seed(31415)
```

# Final Project

## Research Goal/Question

When two proton beams align, collisions of these protons produce elementary (subatomic) particles.

In addition to several other events, a Higgs Boson may be produced (a disturbance in the Higgs Field, related to the mass of particles). 
Moreover, in very special cases, the Higgs Boson may decay and produce a pair of another class of elementary subatomic particles, a pair of tau ($\tau$) leptons.  

The data below was simulated by the ATLAS experiment at CERN.  The primary goal of this project is to evaluate the usage of Random Decision Forests for selecting which primitive or derived values are important for determining if the observed products of a collision contain evidence of decay of the Higgs Boson into a tau-lepton pair (_signal_) or if the detected products were of another variety (_background_).

## Methodology

I will evaluate the usage of Random Decision Forests for variable selection and prediction. 

70 percent of a 250k observation sample of the original data set will be used for training, and evaluated using the remaining 30 percent as a test subset.

A Random Decision Forest will be generated, using 5-fold Cross Validation and the “Out-Of-Bag” prediction accuracy for the “used variables” referenced in the next section. 

Then, the important variables will be identified according to their mean decrease of Gini index (a measure of loss of prediction accuracy when the variable is not present in the tree), computed as an average across cross-validated trees.

Finally, the effectiveness of classification using the Random Forest as a model will be evaluated with the rate of true positive and negative classifications on the test subset.  
Sources of error (identified by the rate of false positives and negatives) will be examined. 


## Data

### Rationale

### Read Data

```{r}
raw_data = read.csv2("./atlas-higgs-challenge-2014-v2.csv", sep=",", header=TRUE)
```

### Build and Filter Working Data

```{r}
# Build data frame of chosen predictors, all as numeric
data = data.frame("DER_mass_transverse_met_lep" = as.numeric(raw_data$DER_mass_transverse_met_lep),
                  "DER_mass_MMC" = as.numeric(raw_data$DER_mass_MMC), 
                  "DER_mass_vis" = as.numeric(raw_data$DER_mass_vis),
                  "DER_pt_h" = as.numeric(raw_data$DER_pt_h),
                  "DER_deltar_tau_lap" = as.numeric(raw_data$DER_deltar_tau_lep),
                  "DER_pt_tot" = as.numeric(raw_data$DER_pt_tot),
                  "DER_sum_pt" = as.numeric(raw_data$DER_sum_pt),
                  "DER_pt_ratio_lep_tau" = as.numeric(raw_data$DER_pt_ratio_lep_tau),
                  "DER_met_phi_centrality" = as.numeric(raw_data$DER_met_phi_centrality),
                  "PRI_tau_pt" = as.numeric(raw_data$PRI_tau_pt),
                  "PRI_tau_eta" = as.numeric(raw_data$PRI_tau_eta),
                  "PRI_tau_phi" = as.numeric(raw_data$PRI_tau_phi),
                  "PRI_lep_pt" = as.numeric(raw_data$PRI_lep_pt),
                  "PRI_lep_eta" = as.numeric(raw_data$PRI_lep_eta),
                  "PRI_lep_phi" = as.numeric(raw_data$PRI_lep_phi),
                  "PRI_met" = as.numeric(raw_data$PRI_met),
                  "PRI_met_phi" = as.numeric(raw_data$PRI_met_phi),
                  "PRI_met_sumet" = as.numeric(raw_data$PRI_met_sumet),
                  "PRI_jet_num" = as.numeric(raw_data$PRI_jet_num),
                  "PRI_jet_all_pt" = as.numeric(raw_data$PRI_jet_all_pt),
                  "Label" = as.factor(raw_data$Label)
)
```

#### Filter out observations which had null values

```{r}
# filter out observations which have No Value for the Higgs candidate mass
filtered = dplyr::filter(data, DER_mass_MMC > -999.0)

set.seed(31415)
# Use 300k of the observations to train and validate
sample_indx = sample(nrow(filtered), 
                     300000,
                     replace=F)
project_data = filtered[sample_indx,]
```

#### Training/Test Split

```{r}
# Hold out 30% from training sample, build the training subset
num_val <- floor(nrow(project_data) * 0.3)  # Number held out for validation subset
num_train <- nrow(project_data) - num_val
training_indx <- sample(nrow(project_data), 
                        num_train, 
                        replace=F)

training <- project_data[training_indx,]
validation <- project_data[-training_indx,]
```

## Random Forest

### Train The Model

```{r}
# training control
ctrl <- trainControl("repeatedcv",              # Do k-Folds CV to estimate error, tune parameters
                     number = 5,                # Do 5-fold CV to avoid melting the memory in my laptop
                     allowParallel = TRUE,      # If parallelized backend available, use it
                     classProbs = TRUE,         # Save the probabilities of each class, averaged from trees
                     verboseIter = TRUE) #,     # Produce verbose output when training
                     #savePredictions = TRUE)

# Model Tuning Parameters
tgrid <- expand.grid(
  # Only choose 4,5,6 and sqrt(# predictors) for random subset of vars
  mtry = c(4, sqrt(ncol(project_data)), 5, 6, 7, 8, 9, 10),
  # Make sure to split trees according to node impurity
  splitrule = "gini",
  # Ensure each decision tree splits twice, and compare the two
  min.node.size = c(2)
)

set.seed(31415)
rf_model <- train(Label ~ .,                # Outcome: Label: {b,s}; as a response of all other predictors
                  data = training,          # Use the pre-specified training subset
                  method = "ranger",        # use `ranger' package implementation of Random Forest
                  importance = "impurity",  # Measure Gini Index of Node Impurity
                  num.trees = 250,          # Only grow 250 trees, save memory
                  tuneGrid = tgrid,         # Use specified tuning parameters
                  trControl = ctrl,         # Use training control specified earlier
                  verbose=T)                # Enable Verbose output for timing
```

### Which number of random subset of variables resulted in a higher accuracy rate?

```{r}
# Plot Accuracy vs the number of randomly selected predictors for each decision tree
plot(rf_model)
```

```{r}
# Print the best-accuracy number of randomly selected variables
# for each decision tree.
print(rf_model$bestTune$mtry)
```

Looks like we should be using 5 randomly selected variables for each predictor, as it maximizes the accuracy rate of prediction.

### Test the model on the validation subset

```{r}
pred = predict(rf_model, newdata = validation)

```

### AUC-ROC Curves

```{r}

```

### Confusion Matrix - True/False Positives on Validation Set

```{r}
confusionMatrix(pred, validation$Label)
```

### Variable Importance measures

```{r}
varImp(rf_model)
```

<br>

<br>

<br>